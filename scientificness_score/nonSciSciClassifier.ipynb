{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b9e632-395d-4f9e-bbf9-1ed7d4fe71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "\n",
    "datasetsize = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f918f-7f6a-4e5b-93c5-b77302385036",
   "metadata": {},
   "source": [
    "# Load Files\n",
    "\n",
    "use datasets to load custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8c46b7-d6d1-4522-a2c4-aa96f799cef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1e107711fefada7b\n",
      "Reusing dataset text (/home/jmuecke/.cache/huggingface/datasets/text/default-1e107711fefada7b/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348c9118055443d780ed0e4e07f97457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-4dcfe7a40d2292c0\n",
      "Reusing dataset text (/home/jmuecke/.cache/huggingface/datasets/text/default-4dcfe7a40d2292c0/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717dd28eab854a2d81010b40063192d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5ca599a2d7c3ec25\n",
      "Reusing dataset text (/home/jmuecke/.cache/huggingface/datasets/text/default-5ca599a2d7c3ec25/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520a9c18e3d94faabe5dea8973f18a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6242e45549efde32\n",
      "Reusing dataset text (/home/jmuecke/.cache/huggingface/datasets/text/default-6242e45549efde32/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b608d2c289c4561989ce532b9ba7749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ca57685d8139194\n",
      "Reusing dataset text (/home/jmuecke/.cache/huggingface/datasets/text/default-9ca57685d8139194/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac6bbea2c054b278c612b5e56a381c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-02cfabfaaa2f7bbb\n",
      "Reusing dataset text (/home/jmuecke/.cache/huggingface/datasets/text/default-02cfabfaaa2f7bbb/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e63d79d9cec43a48f730b6fb6276fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8550a081db9ac104\n",
      "Reusing dataset text (/home/jmuecke/.cache/huggingface/datasets/text/default-8550a081db9ac104/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f62989621e0430d91183940da956099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-30d022aabe053e40\n",
      "Reusing dataset text (/home/jmuecke/.cache/huggingface/datasets/text/default-30d022aabe053e40/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7a404db7e54e6692949205b81676c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "datasetSciAs = load_dataset(\"text\",data_files='/media/nvme3n1/proj_scisen/datasets/SciSen-as.txt')\n",
    "datasetSciA= load_dataset(\"text\",data_files='/media/nvme3n1/proj_scisen/datasets/SciSen-a.txt')\n",
    "datasetSciB = load_dataset(\"text\",data_files='/media/nvme3n1/proj_scisen/datasets/SciSen-b.txt')\n",
    "datasetSciC = load_dataset(\"text\",data_files='/media/nvme3n1/proj_scisen/datasets/SciSen-c.txt')\n",
    "#datasetnonSciReddit = load_dataset(\"text\",data_files='/media/nvme3n1/proj_scisen/datasets/RedditSen.txt')\n",
    "datasetnonSci1 = load_dataset(\"text\",data_files='/media/nvme3n1/proj_scisen/datasets/ScifiSen1.txt')\n",
    "datasetnonSci2 = load_dataset(\"text\",data_files='/media/nvme3n1/proj_scisen/datasets/RedditSen.txt')\n",
    "datasetnonSci3 = load_dataset(\"text\",data_files=\"/media/nvme3n1/proj_scisen/datasets/ukraineTweets.txt\")\n",
    "datasetnonSci4 = load_dataset(\"text\",data_files='/media/nvme3n1/proj_scisen/datasets/ScifiSen2.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7be17d-ac02-4ec2-95c5-70bc1ac98d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "from datasets import DatasetDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b3550-14a5-4264-b491-d445ca0bccdf",
   "metadata": {},
   "source": [
    "\n",
    "# Label data\n",
    "\n",
    "label each entry in each dataset with the corrosponding label\n",
    "\n",
    "    - scientific sentence -> label = 1\n",
    "    - non scientific sentence -> label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cdc78d-9488-498e-9fff-3023498dca54",
   "metadata": {},
   "outputs": [],
   "source": [
    " def label_dataset(label, dataset):\n",
    "    return dataset['train'].add_column('label', column= [label]*len(dataset['train']))\n",
    "\n",
    "#Labels: Sci= 1 NonSci=0\n",
    "datasetSciAs['train'] = label_dataset(float(0.9),datasetSciAs)\n",
    "datasetSciA['train'] = label_dataset(float(0.9),datasetSciA)\n",
    "datasetSciB['train'] = label_dataset(float(0.9),datasetSciB)\n",
    "datasetSciC['train'] = label_dataset(float(0.9),datasetSciC)\n",
    "\n",
    "#datasetnonSciReddit['train'] = label_dataset(0,datasetnonSciReddit)\n",
    "datasetnonSci1['train'] = label_dataset(float(0.1),datasetnonSci1)\n",
    "datasetnonSci2[\"train\"] = label_dataset(float(0.1),datasetnonSci2)\n",
    "datasetnonSci3[\"train\"] = label_dataset(float(0.1),datasetnonSci3)\n",
    "datasetnonSci4[\"train\"] = label_dataset(float(0.1),datasetnonSci4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fec3809-70f3-4ae1-a531-1dfe47deff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvalSciAs = datasetSciAs[\"train\"].select(range(0,int(len(datasetSciAs[\"train\"])*0.1)))\n",
    "EvalSciA = datasetSciAs[\"train\"].select(range(0,int(len(datasetSciAs[\"train\"])*0.1)))\n",
    "EvalSciB = datasetSciAs[\"train\"].select(range(0,int(len(datasetSciAs[\"train\"])*0.1)))\n",
    "EvalSciC = datasetSciAs[\"train\"].select(range(0,int(len(datasetSciAs[\"train\"])*0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ba729f-a1f8-4463-941e-1b9271350cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/jmuecke/.cache/huggingface/datasets/text/default-9ca57685d8139194/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08/cache-034e0f64220a236b.arrow\n",
      "Loading cached shuffled indices for dataset at /home/jmuecke/.cache/huggingface/datasets/text/default-1e107711fefada7b/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08/cache-130709a07898da91.arrow\n"
     ]
    }
   ],
   "source": [
    "datasetSci = concatenate_datasets([\n",
    "    datasetSciAs[\"train\"].select(range(int(len(datasetSciAs[\"train\"])*0.1)+1, len(datasetSciAs[\"train\"])-1)),\n",
    "    datasetSciA[\"train\"].select(range(int(len(datasetSciA[\"train\"])*0.1)+1, len(datasetSciA[\"train\"])-1)),\n",
    "    datasetSciB[\"train\"].select(range(int(len(datasetSciAs[\"train\"])*0.1)+1, len(datasetSciB[\"train\"])-1)),\n",
    "    datasetSciC[\"train\"].select(range(int(len(datasetSciAs[\"train\"])*0.1)+1, len(datasetSciC[\"train\"])-1))\n",
    "])\n",
    "    \n",
    "datasetnonSci = concatenate_datasets([\n",
    "    datasetnonSci1[\"train\"], \n",
    "    datasetnonSci2[\"train\"], \n",
    "    datasetnonSci3[\"train\"], \n",
    "    datasetnonSci4[\"train\"]\n",
    "])\n",
    "datasetnonSci = datasetnonSci.shuffle(seed=42)\n",
    "datasetSci = datasetSci.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a175698-b4b4-400f-8246-b4d779c02dfe",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "\n",
    "concatenate all the small parts into one big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25aa2a10-3eef-4840-b726-d5b106f63cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/jmuecke/.cache/huggingface/datasets/text/default-1e107711fefada7b/0.0.0/acc32f2f2ef863c93c2f30c52f7df6cc9053a1c2230b8d7da0d210404683ca08/cache-9c62349a87f23eed.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = concatenate_datasets([datasetSci,datasetnonSci])\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = DatasetDict({'train':dataset.select(range(0, int(len(dataset)*0.72))),'test':dataset.select(range((int(len(dataset)*0.72)) +1, len(dataset)))})\n",
    "\n",
    "#TODO split data and don't use \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76648bd9-d95b-49c0-852c-aedac757ff07",
   "metadata": {},
   "source": [
    "# Tokenize Dataset\n",
    "\n",
    "to train, the dataset has to be tokanized, the base model used is a scibert trained on cased sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6de65b3-16f4-4207-8546-a7a72b01c8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_function at 0x7f66ef44d4c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecbd5e80bb4461891db8af749120147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2554653 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6be7f7d0994c0a91273c0b530923e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/993476 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer          = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_cased\")\n",
    "\n",
    "trainlabels        = dataset[\"train\"][\"label\"]\n",
    "testlabels         = dataset[\"test\"][\"label\"]\n",
    "\n",
    "def tokenize_function(dataset):\n",
    "    return tokenizer(dataset[\"text\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors = \"np\")\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a1acf9-b764-4e26-ad57-e166b424c92c",
   "metadata": {},
   "source": [
    "# Fix Dataset Error\n",
    "For some reason the tokenizer creates the input_ids like this: [[ids]] but we need them like this: [ids]. \n",
    "Because of this, we transform them into an numpy array to squeeze the wrong dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87170a0-c972-4d69-8fe2-8a4365fa5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "idarray          = np.array(tokenized_datasets[\"train\"][\"input_ids\"])\n",
    "idlist           = idarray.squeeze(1)\n",
    "tokentypearray   = np.array(tokenized_datasets[\"train\"][\"token_type_ids\"])\n",
    "tokentypelist    = tokentypearray.squeeze(1)\n",
    "attentionarray   = np.array(tokenized_datasets[\"train\"][\"attention_mask\"])\n",
    "attentionlist    = attentionarray.squeeze(1)\n",
    " \n",
    "training_dataset = {\"text\"           : tokenized_datasets[\"train\"][\"text\"],\n",
    "                    \"label\"          : tokenized_datasets[\"train\"][\"label\"],\n",
    "                    \"input_ids\"      : idlist,\n",
    "                    \"token_type_ids\" : tokentypelist, \n",
    "                    \"attention_mask\" : attentionlist}\n",
    "\n",
    "training_dataset = Dataset.from_dict(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecdced-1658-42db-a6f3-0986d588a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "idarray            = np.array(tokenized_datasets[\"test\"][\"input_ids\"])\n",
    "idlist             = idarray.squeeze(1)\n",
    "tokentypearray     = np.array(tokenized_datasets[\"test\"][\"token_type_ids\"])\n",
    "tokentypelist      = tokentypearray.squeeze(1)\n",
    "testattentionarray = np.array(tokenized_datasets[\"test\"][\"attention_mask\"])\n",
    "testattentionlist  = testattentionarray.squeeze(1)\n",
    "\n",
    "test_dataset       = {\"text\"           : tokenized_datasets[\"test\"][\"text\"],\n",
    "                      \"label\"          : tokenized_datasets[\"test\"][\"label\"],\n",
    "                      \"input_ids\"      : idlist,\n",
    "                      \"token_type_ids\" : tokentypelist, \n",
    "                      \"attention_mask\" : testattentionlist}\n",
    "\n",
    "test_dataset       = Dataset.from_dict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31be1c2-ef04-497d-b101-e72b12d2f2ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize Model\n",
    "\n",
    "We initialize the preTrained SciBert Model https://huggingface.co/allenai/scibert_scivocab_cased \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb702a-6dca-4c57-bb6b-ccecf2352fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoModel\n",
    "import torch \n",
    "name : str() = \"SciBertFull\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained('allenai/scibert_scivocab_cased', num_labels=1, ignore_mismatched_sizes=True, hidden_dropout_prob=0.1, attention_probs_dropout_prob=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0e4e2-ad96-45fc-bd05-6a8d2b747e84",
   "metadata": {},
   "source": [
    "# Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97021c33-19a3-4225-9210-b8f5d5dbea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    single_squared_errors = ((logits - labels).flatten()**2).tolist()\n",
    "    \n",
    "    # Compute accuracy \n",
    "    # Based on the fact that the rounded score = true score only if |single_squared_errors| < 0.5\n",
    "    accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad22065-7bd7-43d2-9570-e45da8486cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c5406-5f7a-4328-b14c-e0851af42789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"nonSciSciClass_trainer\", \n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  save_total_limit=2,\n",
    "                                  num_train_epochs=5,\n",
    "                                  metric_for_best_model=\"accuracy\",\n",
    "                                  report_to=\"wandb\",\n",
    "                                  run_name=name,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  weight_decay=0.05,\n",
    "                                  learning_rate=1e-5\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2822a-429d-452e-a703-912633000631",
   "metadata": {},
   "source": [
    "# Load Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3c93f-98e2-4dee-9829-e33500d49ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=training_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics_for_regression,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182fc804-b878-4b2e-a16d-353e13771a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env WANDB_PROJECT=huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be165629-a87c-49d3-aa68-43a5289b6ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2554653\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 399165\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjustinmuecke\u001b[0m (\u001b[33mscise\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/nvme3n1/proj_scisen/git_repos/git_repos_justin/22_scisen/wandb/run-20230117_004101-3ib08jl1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/scise/huggingface/runs/3ib08jl1\" target=\"_blank\">SciBertFull</a></strong> to <a href=\"https://wandb.ai/scise/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/transformers/trainer.py:1498\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1495\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1497\u001b[0m )\n\u001b[0;32m-> 1498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/transformers/trainer.py:1740\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1743\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1744\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1746\u001b[0m ):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/transformers/trainer.py:2470\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2470\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2473\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/transformers/trainer.py:2502\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2501\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2502\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2504\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:158\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_device_obj:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule must have its parameters and buffers \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon device \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (device_ids[0]) but found one of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem on device: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_device_obj, t\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m--> 158\u001b[0m inputs, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# for forward function without any inputs, empty list and dict will be created\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# so the module can be executed on one device which is the first one in device_ids\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inputs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:175\u001b[0m, in \u001b[0;36mDataParallel.scatter\u001b[0;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, kwargs, device_ids):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:45\u001b[0m, in \u001b[0;36mscatter_kwargs\u001b[0;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Scatter with support for kwargs dictionary\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m inputs \u001b[38;5;241m=\u001b[39m scatter(inputs, target_gpus, dim) \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m---> 45\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(kwargs):\n\u001b[1;32m     47\u001b[0m     inputs\u001b[38;5;241m.\u001b[39mextend(() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)))\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:36\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# After scatter_map is called, a scatter_map cell will exist. This cell\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# has a reference to the actual function scatter_map, which has references\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# to a closure that has a reference to the scatter_map cell (because the\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# fn is recursive). To avoid this reference cycle, we set the function to\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# None, clearing the cell\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mscatter_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     scatter_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:27\u001b[0m, in \u001b[0;36mscatter.<locals>.scatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mlist\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(scatter_map, obj))]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mtype\u001b[39m(obj)(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscatter_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [obj \u001b[38;5;28;01mfor\u001b[39;00m targets \u001b[38;5;129;01min\u001b[39;00m target_gpus]\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:23\u001b[0m, in \u001b[0;36mscatter.<locals>.scatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(scatter_map, obj))]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscatter_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mlist\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(scatter_map, obj))]\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:19\u001b[0m, in \u001b[0;36mscatter.<locals>.scatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter_map\u001b[39m(obj):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mScatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_namedtuple(obj):\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(scatter_map, obj))]\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:96\u001b[0m, in \u001b[0;36mScatter.forward\u001b[0;34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mand\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39minput_device \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# Perform CPU to GPU copies in a background stream\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     streams \u001b[38;5;241m=\u001b[39m [_get_stream(device) \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m target_gpus]\n\u001b[0;32m---> 96\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcomm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Synchronize with the copy stream\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/media/nvme3n1/proj_scisen/venv/lib/python3.8/site-packages/torch/nn/parallel/comm.py:189\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(tensor, devices, chunk_sizes, dim, streams, out)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     devices \u001b[38;5;241m=\u001b[39m [_get_device_index(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m devices]\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m devices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90de564-8a17-4ae9-a507-0d71daba51d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69281556-f8a6-4af2-8fd6-f799b854a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
